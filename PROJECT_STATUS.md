# SpectralFM â€” Project Status

**Last Updated:** Feb 10, 2026
**Total Lines of Code:** ~3,500 (across 15+ Python files)
**Status:** P1-P2 COMPLETE. Architecture fixes + W&B logging done. 19/19 tests passing. Ready for GPU pretraining (P3).

---

## COMPLETED MILESTONES

### âœ… PHASE 1: Make It Run (COMPLETE)
- All 16 smoke tests passing
- Fixed VIBHead missing `kl_loss` key
- Fixed `PhysicsLoss` class alias
- Fixed missing `List` import in trainer.py
- Model forward/backward passes verified

### âœ… PHASE 2A: Classical Baselines (COMPLETE)
- Implemented PDS, SBC, DS, PLS in `src/evaluation/baselines.py`
- Fixed critical transfer direction bug (targetâ†’source space)
- Baseline results on corn m5â†’mp6 (30 transfer samples):
  - DS: RÂ²=0.69, RMSEP=0.22
  - SBC: RÂ²=0.38, RMSEP=0.31
  - PDS: RÂ²=-5.50 (poor due to limited samples)
  - No Transfer: RÂ²=-21.46 (expected failure)
  - Target Direct: RÂ²=0.69 (upper bound)
- SpectralFM fine-tuning test completed (random init, no pretrain)

### âœ… PHASE 2B: Pretraining Data Pipeline (COMPLETE)
- Built pretraining corpus v2: **61,420 spectra** (15,355 real from 2 sources + 3Ã— augmentation)
- File: `data/pretrain/spectral_corpus_v2.h5` (0.47 GB)
- Sources: RRUFF (9,941 Raman) + OpenSpecy (4,778 Raman + 636 FTIR)
- Created `src/data/corpus_downloader.py` with downloaders for:
  - RRUFF (mineral Raman/IR from JCAMP-DX)
  - OpenSpecy (experimental Raman + FTIR from RDS format)
  - ChEMBL (computed Raman+IR via DFT Lorentzian broadening â€” ready, not downloaded)
  - USPTO (computed IR from Parquet â€” ready, not downloaded)
- Created `scripts/build_corpus_v2.py` (multi-source assembly + augmentation + validation)
- Created `src/data/pretraining_pipeline.py` with:
  - SNV normalization and 2048-point resampling
  - Data augmentation (noise, baseline drift, wavelength shift, intensity scaling)
- Updated `PretrainHDF5Dataset` with v2 format, source/type filtering, corpus stats logging
- Created `scripts/run_pretrain.py` for pretraining loop
- Verified pretraining pipeline (20 steps test: loss 1.29 â†’ 0.90)

### âœ… P2: Architecture Fixes + W&B Integration (COMPLETE)
- **pywt Wavelet:** Replaced Haar approximation with real Daubechies-4 DWT via PyWavelets in `embedding.py`
- **LoRA Injection:** Created `src/models/lora.py` (LoRALinear, inject_lora, state dict extraction). Targets q/k/v projections in transformer. ~0.4% of backbone params.
- **Dual Logging:** Created `src/utils/logging.py` (ExperimentLogger) with simultaneous W&B + JSONL backend. Graceful fallback if wandb unavailable.
- Integrated ExperimentLogger into PretrainTrainer and FinetuneTrainer
- Added W&B CLI flags to `scripts/run_pretrain.py`
- Added 3 new smoke tests (wavelet_pywt, lora_injection, logger)
- **All 19/19 smoke tests passing**
- 5-step pretraining sanity check verified with pywt + JSONL logging

---

## FILE-BY-FILE STATUS

### âœ… Data (READY)
| File | Status | Notes |
|------|--------|-------|
| `data/processed/corn/*.npy` | âœ… Ready | 80 samples, 3 instruments (m5, mp5, mp6), 700 channels, 4 properties |
| `data/processed/tablet/*.npy` | âœ… Ready | 655 samples, 2 instruments, 650 channels, 3 properties |
| `data/raw/corn/corn.mat` | âœ… Ready | Original MATLAB file |
| `data/raw/tablet/nir_shootout_2002.mat` | âœ… Ready | Original MATLAB file |
| `data/pretrain/spectral_corpus_v2.h5` | âœ… Ready | 61,420 spectra (15,355 real), 2048 channels, 0.47 GB |

### âœ… Config (252 lines) â€” WORKING
`src/config.py`
- All hyperparameters defined as nested dataclasses
- Added `get_light_config()` for fast CPU testing
- Lightweight config: 64-dim model, 254K params

### âœ… Datasets (500+ lines) â€” WORKING
`src/data/datasets.py`
- Corn and Tablet dataset classes âœ…
- Augmentation pipeline âœ…
- Resampling to 2048 points âœ…
- **Added:** `PretrainHDF5Dataset` for large-scale corpus loading âœ…
- **Updated:** v2 format support with source/type filtering âœ…
- **Added:** `build_hdf5_pretrain_loader()` âœ…

### âœ… Corpus Downloader (NEW) â€” WORKING
`src/data/corpus_downloader.py`
- RRUFFDownloader: JCAMP-DX parser, Raman spectra âœ…
- OpenSpecyDownloader: RDS format parser, Raman + FTIR âœ…
- ChEMBLDownloader: SQLite + Lorentzian broadening (ready, untested at scale)
- USPTODownloader: Parquet IR spectra (ready, untested at scale)

### âœ… Wavelet Embedding (214 lines) â€” WORKING
`src/models/embedding.py`
- Verified: forward pass works with pretraining pipeline
- WaveletEmbedding + WavenumberPE + CLS/domain tokens all functional
- **P2:** Now uses pywt Daubechies-4 DWT instead of Haar approximation

### âœ… LoRA (NEW) â€” WORKING
`src/models/lora.py`
- LoRALinear wrapper, inject_lora tree walker, state dict extraction
- Targets q_proj, k_proj, v_proj in transformer attention

### âœ… Experiment Logger (NEW) â€” WORKING
`src/utils/logging.py`
- Dual W&B + JSONL backend
- Integrated into PretrainTrainer and FinetuneTrainer

### âœ… Mamba Backbone (201 lines) â€” WORKING
`src/models/mamba.py`
- Pure PyTorch implementation of selective SSM (no CUDA kernels)
- SelectiveSSM: Î” projection, A/B/C/D parameters, discretization, selective scan
- MambaBlock: norm â†’ SSM â†’ residual
- MambaBackbone: stack of MambaBlock layers
- **Known limitation:** Pure PyTorch scan is O(n) but slow constant factor; `mamba-ssm` CUDA kernels are 5-10Ã— faster
- **Potential issue:** Parallel scan (`pscan`) is mentioned in config but may not be implemented â€” verify the forward pass uses sequential scan, which works but is slow
- **Potential issue:** Discretization of continuous SSM params (A, B) via ZOH â€” verify math

### âœ… MoE + KAN (240 lines) â€” WORKING
`src/models/moe.py`
- Verified: forward pass works in pretraining pipeline
- MoE balance loss being computed (shows 0.0000 but functional)

### âœ… Transformer (103 lines) â€” WORKING
`src/models/transformer.py`
- Verified: works in pretraining pipeline

### âœ… Heads (316 lines) â€” WORKING
`src/models/heads.py`
- VIBHead: Fixed missing `kl_loss` key âœ…
- ReconstructionHead: works with MSRP âœ…
- RegressionHead: verified in fine-tuning test âœ…

### âœ… Losses (429 lines) â€” WORKING
`src/losses/losses.py`
- Added `PhysicsLoss` alias âœ…
- MSRP, Physics, VIB losses all computing correctly
- POT library installed for OT loss

### âœ… Trainer (403 lines) â€” WORKING
`src/training/trainer.py`
- Fixed missing `List` import âœ…
- PretrainTrainer verified: 20-step test passed
- Loss decreasing: 1.29 â†’ 0.90

### âœ… Baselines (335 lines) â€” WORKING (NEW)
`src/evaluation/baselines.py`
- PLS, PDS, SBC, DS implemented
- Fixed transfer direction bug
- Results saved to `experiments/baselines_corn.json`

### ğŸŸ¡ Metrics (229 lines) â€” LIKELY OK
`src/evaluation/metrics.py`
- Standard regression metrics work (used in baselines)
- Conformal prediction untested

---

## NEXT STEPS (P3: Pretraining)

### Immediate
1. **Run full pretraining** (50K+ steps on GPU â€” Colab A100)
   ```bash
   python scripts/run_pretrain.py --max-steps 50000 --batch-size 64 --wandb
   ```

2. **Fine-tune on corn with pretrained model**
   - Load checkpoint from pretraining
   - LoRA fine-tuning with 10, 20, 30 transfer samples
   - Compare to baselines (DS RÂ²=0.69, target: RÂ²>0.95)

### Later
3. TTT (Test-Time Training) evaluation â€” zero-shot transfer
4. Full experiment suite (E1-E12)
5. Ablation studies
6. Paper writing

---

## WHAT WORKS (Verified)

- âœ… All 19 smoke tests passing (16 original + 3 P2)
- âœ… Config loads correctly
- âœ… Corn data loads: shape (80, 700), wavelengths (700,), properties (80, 4)
- âœ… Tablet data loads: calibrate (155, 650), test (460, 650), validate (40, 650)
- âœ… Pretraining corpus v2: 61,420 spectra (15,355 real from RRUFF + OpenSpecy)
- âœ… Pretraining pipeline: loss decreasing (1.29 â†’ 0.90 in 20 steps)
- âœ… Baselines: DS RÂ²=0.69, SBC RÂ²=0.38 on corn transfer
- âœ… SpectralFM fine-tuning: pipeline works (random init)

## WHAT'S UNTESTED

- â“ Full pretraining (50K+ steps)
- â“ Pretrained model fine-tuning
- â“ FNO transfer head (needs testing)
- â“ Conformal prediction
- ~~â“ LoRA injection~~ âœ… Verified in smoke test
- â“ TTT (Test-Time Training)

---

## DATA STATUS

### âœ… Downloaded and Ready
- **RRUFF Raman** (9,941 spectra from JCAMP-DX files)
- **OpenSpecy Raman** (4,778 spectra from RDS)
- **OpenSpecy FTIR** (636 spectra from RDS)
- **Total real:** 15,355 spectra â†’ 61,420 with 3Ã— augmentation
- Corn and Tablet benchmark datasets

### Not Downloaded (Ready to Download for More Pretraining Data)
- ChEMBL IR-Raman (~220K spectra, ~10.4 GB download) â€” downloader ready
- USPTO-Spectra (~177K spectra, ~8.1 GB download) â€” downloader ready
- NIST IR (~5.2K) â€” no downloader yet
